# Project Name: RealTimeASLTranslator

## Description

RealTimeASLTranslator is a ML project that leverages the power of Tensorflow Object Detection API and CUDA Toolkit to create a real-time American Sign Language (ASL) hand symbol translator. This project enables the translation of ASL gestures into corresponding English words and letters during live video, making it a valuable tool for communication, especially in video conferencing scenarios.

## Project Demo

Check out a live demonstration of the RealTimeASLTranslator in action!

[![Project Demo](https://img.youtube.com/vi/qPPTqYmnSp4/0.jpg)](https://www.youtube.com/watch?v=qPPTqYmnSp4)

## Key Features

- **Real-Time Translation:** Utilize Tensorflow Object Detection API and CUDA Toolkit to achieve real-time translation of ASL hand symbols into English text.

- **Live Video Integration:** Seamlessly integrate the translator into live video streams, enabling on-the-fly translation of ASL gestures during video conferencing and other applications.

- **Accurate Detection:** Benefit from the accuracy of object detection models to precisely identify ASL hand symbols in various lighting conditions and orientations.

- **English Transcription:** Transcribe the recognized ASL gestures into corresponding English words or letters, enhancing communication accessibility.

## Project Directory Overview

- `.ipynb_checkpoints/`: Contains test cases for the Python script.

- `Tensorflow/`: Holds relevant dependencies for the Tensorflow Object Detection package.

- `Project Demo.md`: Provides a link to a YouTube video demonstrating the project in action.

- `Script.ipynb`: Contains the main Python script responsible for running the RealTimeASLTranslator project.

## Installation

1. Clone this repository to your local machine.
git clone https://github.com/username/RealTimeASLTranslator.git


2. Navigate to the project directory.
cd RealTimeASLTranslator


3. Set up the required dependencies for the project, including Tensorflow and CUDA Toolkit.

4. Run the `Script.ipynb` notebook to launch the RealTimeASLTranslator.

## Usage

1. Launch the Jupyter notebook `Script.ipynb` by following the installation instructions above.

2. Follow the notebook instructions to load the required models and set up the real-time ASL translation.

3. Access live video feeds (e.g., webcam) to start translating ASL hand symbols into English text.

4. Experiment with different gestures and observe the accurate translations.

---

Thank you for exploring RealTimeASLTranslator! We're excited about the potential this project has to enhance communication and accessibility. We value your feedback and suggestions as we continue to improve and expand this innovative solution. Enjoy translating ASL gestures in real-time!
